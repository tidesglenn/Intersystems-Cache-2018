; DrillTimeThree
; Traverses global structures and maps data to CSV rows based on class metadata.
; Compatible with Caché 2018. Uses %Dictionary.ClassDefinition for property metadata.
;
DrillTimeThree(pGlobal, pClass, pKeyList)
    new $ZERROR, $ZTRAP
    set $ZTRAP="TRAP^DrillTimeThree"

    new keyLength, keyFields, fieldMap, classDef, sc
    new seq, propName, propObj, skip, type, coll, outputProps, i, val, recCount, fieldNodeMap, fieldPieceMap, fieldTypeMap
    set recCount=0

    ; Determine key length from string or count
    set keyLength=1
    if pKeyList'="" {
    . if pKeyList?1N.N {
    . . set keyLength=+pKeyList
    . } else {
    . . set keyLength=$length(pKeyList, ",")
    . . for i=1:1:keyLength set keyFields(i)=$piece(pKeyList,",",i)
    . }
    }

    ; Use ClassDefinition instead of CompiledClass for better compatibility
    set classDef=##class(%Dictionary.ClassDefinition).%OpenId(pClass,.sc)
    if '$isobject(classDef) || $SYSTEM.Status.IsError(sc) {
    . write "ERROR: Class not found or could not open: ",pClass,! quit
    }

    ; Loop through all Properties safely
    for i=1:1:classDef.Properties.Count() {
    . set propObj=classDef.Properties.GetAt(i)
    . if '$isobject(propObj) continue
    . set skip=0
    . if $property(propObj,"Calculated") set skip=1
    . if $property(propObj,"Relationship") set skip=1
    . if $property(propObj,"MultiDimensional") set skip=1
    . set coll=$property(propObj,"Collection") if coll'="" set skip=1
    . set type=$property(propObj,"Type") if type["%Stream" set skip=1
    . if $property(propObj,"Storable")=0 set skip=1
    . if skip quit
    . set propName=$property(propObj,"Name")
    . set seq=$property(propObj,"SequenceNumber") if seq="" set seq=9999
    . set outputProps(seq)=propName
    . set fieldNodeMap(propName)=$property(propObj,"Node")
    . set fieldPieceMap(propName)=$property(propObj,"Piece")
    . set fieldTypeMap(propName)=type
    }

    ; Add CSV header line
    new headerLine set headerLine=""
    for i=1:1 {
    . set propName=$order(outputProps(i)) quit:propName=""
    . if headerLine'="" set headerLine=headerLine_","_""""_propName_"""" else set headerLine="""""_propName_""""
    }
    set ^EXPORT($J,0)=headerLine

    ; Begin recursive traversal from global root
    do Traverse("^"_pGlobal, "", keyLength, pClass, .outputProps, .recCount, .fieldNodeMap, .fieldPieceMap, .fieldTypeMap)
    do WriteCSV(pClass)
    write "Export complete: ",recCount," rows written to CSV.",! quit

TRAP ; Basic error handler
    write "ERROR: ",$zerror,! quit

; Recursive global walker
Traverse(gref, subs, keyLength, className, outputProps, recCount, fieldNodeMap, fieldPieceMap, fieldTypeMap)
    new sub set sub=""
    for {
    . set sub=$order(@(gref_sub)) quit:sub=""
    . new newSubs if subs'="" set newSubs=subs_","_$$Q(sub) else set newSubs=$$Q(sub)
    . new fullRef set fullRef=gref_"("_newSubs_")"
    . new subCount set subCount=$length(newSubs, ",")
    . if subCount<keyLength {
    . . do Traverse(gref, newSubs, keyLength, className, outputProps, .recCount, .fieldNodeMap, .fieldPieceMap, .fieldTypeMap)
    . } else {
    . . if $data(@@fullRef)#10 do ProcessNode(fullRef, className, outputProps, .recCount, .fieldNodeMap, .fieldPieceMap, .fieldTypeMap)
    . . do Traverse(gref, newSubs, keyLength+1, className, outputProps, .recCount, .fieldNodeMap, .fieldPieceMap, .fieldTypeMap)
    . }
    } quit

; Parses node data and maps it to correct CSV fields
ProcessNode(ref, className, outputProps, recCount, fieldNodeMap, fieldPieceMap, fieldTypeMap)
    new val, line, dataNode, prop, i, dataPiece, dataStr, type, joinedVal, obj, sc
    set val=$get(@@ref)
    set line=""
    for i=1:1 {
    . set prop=$order(outputProps(i)) quit:prop=""
    . set dataNode=fieldNodeMap(prop)
    . set dataPiece=fieldPieceMap(prop)
    . set type=fieldTypeMap(prop)
    . if dataPiece'="" {
    . . set dataStr=$piece(val,"^",dataPiece)
    . } else {
    . . set dataStr=val
    . }
    . if type'="" && (type'?1"%".E) {
    . . ; normal scalar
    . } elseif type'"" && (##class(%Dictionary.ClassDefinition).%ExistsId(type)) {
    . . set joinedVal=dataStr
    . . set obj=##class(type).%OpenId(dataStr,.sc)
    . . if $isobject(obj) && '$SYSTEM.Status.IsError(sc) {
    . . . if $property(obj,"Name")'="" set joinedVal=$property(obj,"Name")
    . . . elseif $property(obj,"ID")'="" set joinedVal=$property(obj,"ID")
    . . }
    . . set dataStr=joinedVal
    . }
    . set dataStr=$replace(dataStr,"\"","\"\"")
    . set dataStr=""""_dataStr_""""
    . if line'="" set line=line_","_dataStr else set line=dataStr
    }
    set recCount=recCount+1
    set ^EXPORT($J,recCount)=line
    quit

; Write CSV file from ^EXPORT($J)
WriteCSV(className)
    new file,filePath,line,rec set filePath="C:\\InterSystems\\Cache\\Hackensack\\"_className_".csv"
    set file=##class(%File).%New()
    set file.Name=filePath
    if file.Exists() do file.Delete()
    set sc=file.Open("WNS") if $SYSTEM.Status.IsError(sc) { write "ERROR opening file",! quit }
    for rec=0:1:999999 {
    . quit:'$data(^EXPORT($J,rec))
    . set line=^EXPORT($J,rec)
    . do file.WriteLine(line)
    }
    do file.Close()
    quit

; Quote wrapper for string subscripts
Q(x) if x'?1N.N quit "\""_x_"\"" quit x

; Job spawner stub — can be enhanced for controller logic
RunExportJobs(pGlobal, pClass, pKeyLen)
    new key, count set count=0
    set key=""
    for {
    . set key=$order(@("^"_pGlobal_"("_key_")")) quit:key=""
    . new jobStr set jobStr="do DrillTimeThree(\""_pGlobal_"\",\""_pClass_"\","_key_")"
    . job @jobStr:1:"":5
    . set count=count+1
    }
    write count," jobs launched.",!
    quit
